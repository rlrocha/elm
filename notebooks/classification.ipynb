{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Learning Machine to Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size, random_state=None):\n",
    "    \n",
    "    np.random.seed(seed=random_state) # set random seed\n",
    "\n",
    "    indices = np.arange(X.shape[0]) # arange the indices\n",
    "    np.random.shuffle(indices) # shuffle the indices\n",
    "    \n",
    "    X = X[indices] # assign the shuffled X\n",
    "    y = y[indices] # assign the shuffled y\n",
    "\n",
    "    n_test = int(test_size * X.shape[0]) # calculate the number of test samples\n",
    "    \n",
    "    return X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:] # return the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureNormalization():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.mu = np.mean(X, axis=0) # Mean of each feature\n",
    "        self.sigma = np.std(X, axis=0) # Standard deviation of each feature\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        X_transform = (X-self.mu)/self.sigma # Normalized data (zero mean and unite standard deviation)\n",
    "\n",
    "        return X_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred) # mean of the elements that are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "\n",
    "    n_classes = len(np.unique(y_true)) # Number of classes\n",
    "\n",
    "    cm = np.zeros((n_classes, n_classes)) # initialize the confusion matrix\n",
    "    \n",
    "    for i in range(len(y_true)): # for each sample\n",
    "        cm[y_true[i], y_pred[i]] += 1 # add 1 to the corresponding row and column\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \n",
    "    max = np.max(x, axis=1, keepdims=True) # Returns max of each row and keeps same dims\n",
    "    e_x = np.exp(x - max) # Subtracts each row with its max value\n",
    "    sum = np.sum(e_x, axis=1, keepdims=True) # Returns sum of each row and keeps same dims\n",
    "    f_x = e_x / sum\n",
    "    \n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELMClassifier():\n",
    "\n",
    "    def __init__(self, L, random_state=None):\n",
    "        \n",
    "        self.L = L # number of hidden neurons\n",
    "        self.random_state = random_state # random state\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        M = np.size(X, axis=0) # Number of examples\n",
    "        N = np.size(X, axis=1) # Number of features\n",
    "\n",
    "        np.random.seed(seed=self.random_state) # set random seed\n",
    "\n",
    "        self.w1 = np.random.uniform(low=-1, high=1, size=(self.L, N+1)) # Weights with bias\n",
    "\n",
    "        bias = np.ones(M).reshape(-1, 1) # Bias definition\n",
    "        Xa = np.concatenate((bias, X), axis=1) # Input with bias\n",
    "\n",
    "        S = Xa.dot(self.w1.T) # Weighted sum of hidden layer\n",
    "        H = np.tanh(S) # Activation function f(x) = tanh(x), dimension M X L\n",
    "\n",
    "        bias = np.ones(M).reshape(-1, 1) # Bias definition\n",
    "        Ha = np.concatenate((bias, H), axis=1) # Activation function with bias\n",
    "\n",
    "        # One-hot encoding\n",
    "        n_classes = len(np.unique(y))\n",
    "        y = np.eye(n_classes)[y]\n",
    "\n",
    "        self.w2 = (np.linalg.pinv(Ha).dot(y)).T # w2' = pinv(Ha)*D\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        M = np.size(X, axis=0) # Number of examples\n",
    "        N = np.size(X, axis=1) # Number of features\n",
    "\n",
    "        bias = np.ones(M).reshape(-1, 1) # Bias definition\n",
    "        Xa = np.concatenate((bias, X), axis=1) # Input with bias\n",
    "\n",
    "        S = Xa.dot(self.w1.T) # Weighted sum of hidden layer\n",
    "        H = np.tanh(S) # Activation function f(x) = tanh(x), dimension M X L\n",
    "\n",
    "        bias = np.ones(M).reshape(-1, 1) # Bias definition\n",
    "        Ha = np.concatenate((bias, H), axis=1) # Activation function with bias\n",
    "\n",
    "        y_pred = softmax(Ha.dot(self.w2.T)) # Predictions\n",
    "        \n",
    "        # Revert one-hot encoding\n",
    "        y_pred = np.argmax(y_pred, axis=1) # axis=1 means that we want to find the index of the maximum value in each row\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        M = np.size(X, axis=0) # Number of examples\n",
    "        N = np.size(X, axis=1) # Number of features\n",
    "\n",
    "        bias = np.ones(M).reshape(-1, 1) # Bias definition\n",
    "        Xa = np.concatenate((bias, X), axis=1) # Input with bias\n",
    "\n",
    "        S = Xa.dot(self.w1.T) # Weighted sum of hidden layer\n",
    "        H = np.tanh(S) # Activation function f(x) = tanh(x), dimension M X L\n",
    "\n",
    "        bias = np.ones(M).reshape(-1, 1) # Bias definition\n",
    "        Ha = np.concatenate((bias, H), axis=1) # Activation function with bias\n",
    "\n",
    "        y_pred = softmax(Ha.dot(self.w2.T)) # Predictions\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Iris.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the target: one-hot enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "target_column = 'Species' # Target column\n",
    "specie_list = np.unique(df[target_column]) # Species list\n",
    "\n",
    "print('Species:', specie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species range: [0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0   1            5.1           3.5            1.4           0.2        0\n",
       "1   2            4.9           3.0            1.4           0.2        0\n",
       "2   3            4.7           3.2            1.3           0.2        0\n",
       "3   4            4.6           3.1            1.5           0.2        0\n",
       "4   5            5.0           3.6            1.4           0.2        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_range = np.arange(0, len(specie_list)) # Species range\n",
    "print('Species range:', species_range)\n",
    "\n",
    "i=0\n",
    "for specie in specie_list:\n",
    "    \n",
    "    df[target_column].replace(specie, species_range[i], inplace=True) # Replace species with range\n",
    "\n",
    "    i+=1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[target_column].values # Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels=['Id', target_column], axis=1).values # Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (120, 4)\n",
      "Teste data shape: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(X, y, 0.2) # Split data\n",
    "\n",
    "print('Train data shape:', X_train.shape)\n",
    "print('Teste data shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean: [ 1.92623695e-15  2.46747067e-15 -9.84397749e-16  1.74860126e-16]\n",
      "Train std: [1. 1. 1. 1.]\n",
      "Test mean: [0.18477946 0.04685927 0.20996261 0.10686871]\n",
      "Test std: [1.20007737 1.060218   1.10647033 1.02322103]\n"
     ]
    }
   ],
   "source": [
    "fn = FeatureNormalization() # Feature normalization\n",
    "fn.fit(X_train)\n",
    "\n",
    "# Normalized data (zero mean and unite standard deviation)\n",
    "X_train = fn.transform(X_train)\n",
    "X_test = fn.transform(X_test)\n",
    "\n",
    "print('Train mean:', np.mean(X_train, axis=0))\n",
    "print('Train std:', np.std(X_train, axis=0))\n",
    "print('Test mean:', np.mean(X_test, axis=0))\n",
    "print('Test std:', np.std(X_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hidden neuros: 15\n"
     ]
    }
   ],
   "source": [
    "L = 15 # Number of hidden neurons\n",
    "\n",
    "print('Number of hidden neuros:', L)\n",
    "\n",
    "elm = ELMClassifier(L=L, random_state=42) # ELM\n",
    "elm.fit(X_train, y_train) # Train\n",
    "\n",
    "y_train_pred = elm.predict(X_train) # Train predictions\n",
    "y_test_pred = elm.predict(X_test) # Test predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model: save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/elm_clf.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "joblib.dump(elm, '../models/elm_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hidden neurons: 15\n",
      "Random state: 42\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "elm = joblib.load('../models/elm_clf.pkl')\n",
    "\n",
    "print(f'Number of hidden neurons: {elm.L}')\n",
    "print(f'Random state: {elm.random_state}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (%): 95.83333333333334\n",
      "Testing accuracy (%): 90.0\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy(y_train, y_train_pred)\n",
    "test_acc = accuracy(y_test, y_test_pred)\n",
    "\n",
    "print('Training accuracy (%):', train_acc*100)\n",
    "print('Testing accuracy (%):', test_acc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.,  0.,  0.],\n",
       "       [ 0.,  7.,  1.],\n",
       "       [ 0.,  2., 11.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0            5.1           3.5            1.4           0.2        0\n",
       "1            4.9           3.0            1.4           0.2        0\n",
       "2            4.7           3.2            1.3           0.2        0\n",
       "3            4.6           3.1            1.5           0.2        0\n",
       "4            5.0           3.6            1.4           0.2        0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(labels=['Id'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example: SepalLengthCm    5.2\n",
      "SepalWidthCm     4.1\n",
      "PetalLengthCm    1.5\n",
      "PetalWidthCm     0.1\n",
      "Species          0.0\n",
      "Name: 32, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0, len(data)) # select a random example\n",
    "\n",
    "x_data = data.drop(labels=[target_column], axis=1).iloc[i].values\n",
    "y_label = data[target_column].iloc[i]\n",
    "\n",
    "print('Single example:', data.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [5.2 4.1 1.5 0.1]\n",
      "Target = 0 and class = Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print('Data:', x_data)\n",
    "print('Target = %d and class = %s' % (y_label, specie_list[y_label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.reshape(1, -1) # Reshape data\n",
    "\n",
    "x_data = fn.transform(x_data) # Normalized data (zero mean and unite standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Predicted class: [[0.59478226 0.20218818 0.20302956]]\n"
     ]
    }
   ],
   "source": [
    "y_data_pred = elm.predict_proba(x_data)\n",
    "\n",
    "print('Class:', y_label)\n",
    "print('Predicted class:', y_data_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e3763a57b4ffe0d06e963ec4b7f8ef3a748cbfdb342037439726ee83e94c05b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
